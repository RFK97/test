{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그냥 일렬로 x1 y1 x2 y2 ... 한 facial landmark 를 가지고 학습\n",
    "#단순한 real/fake logistic regression. 4 layer\n",
    "learning_rate = 0.00015\n",
    "training_epochs =10000\n",
    "batch_size = 100\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAW_POINTS = list(range(0, 17))\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "MOUTH_POINTS = list(range(48, 61))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음배치로 넘겨주는 함수!\n",
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\je\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\je\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "c:\\users\\je\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "a = pandas.read_csv('real_points.csv').as_matrix()\n",
    "x_real = a[:,1:-1]\n",
    "y_real = a[:,[-1]]\n",
    "\n",
    "b = pandas.read_csv('fake_points.csv').as_matrix()\n",
    "x_fake = b[:,1:-1]\n",
    "y_fake = b[:,[-1]]\n",
    "\n",
    "c = pandas.read_csv('test_points.csv').as_matrix()\n",
    "x_test = c[:,1:-1]\n",
    "y_test = c[:,[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.append(x_real,x_fake,axis=0)\n",
    "y_data = np.append(y_real,y_fake,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,[None,136])\n",
    "Y=tf.placeholder(tf.float32,[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0=tf.Variable(tf.random_normal([136,68]))\n",
    "b0 = tf.Variable(tf.random_normal([68]))\n",
    "layer0 = tf.nn.relu(tf.matmul(X,w0)+b0)\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([68,34]))\n",
    "b1 = tf.Variable(tf.random_normal([34]))\n",
    "layer1 = tf.nn.relu(tf.matmul(layer0,w1)+b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([34, 17]))\n",
    "b2 = tf.Variable(tf.random_normal([17]))\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,w2)+b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([17, 1]))\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "logits = tf.matmul(layer2,w3)+b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started.\n",
      "Epoch: 0001 cost :317045.11850420636\n",
      "Epoch: 0002 cost :9.850288788477581\n",
      "Epoch: 0003 cost :9.80775169531504\n",
      "Epoch: 0004 cost :9.290459076563518\n",
      "Epoch: 0005 cost :8.947839697202046\n",
      "Epoch: 0006 cost :9.32094689210256\n",
      "Epoch: 0007 cost :8.839294989903767\n",
      "Epoch: 0008 cost :8.968260765075684\n",
      "Epoch: 0009 cost :7.776162902514139\n",
      "Epoch: 0010 cost :7.682204802831014\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning started.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(x_data.shape[0]/ batch_size)\n",
    "\n",
    "    for step in range(total_batch):\n",
    "        batch_xs, batch_ys = next_batch(batch_size,x_data,y_data)\n",
    "        cost_val,_= sess.run([cost,optimizer],feed_dict={X:batch_xs,Y:batch_ys})\n",
    "        avg_cost += cost_val/total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), \"cost :{}\".format(avg_cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]\n",
      " [ 19.45029449]]\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.cast(logits >0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), tf.float32))\n",
    "probable = tf.nn.sigmoid(logits)\n",
    "ac,pred,prob = sess.run([accuracy,predicted,probable], feed_dict={X:x_test, Y:y_test})\n",
    "\n",
    "print(prob)\n",
    "print(sess.run(logits,feed_dict={X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
